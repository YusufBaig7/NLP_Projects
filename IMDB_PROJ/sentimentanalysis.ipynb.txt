{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport seaborn as sns\nimport pandas as pd\nimport tensorflow.keras.datasets.imdb as imdb\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\nfrom collections import Counter","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_tweet(tweet):\n    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre = df['review']\ntweet = []\nfor item in pre:\n    tweet.append(clean_tweet(item))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sent = df['sentiment']\nsentiment = []\nfor item in sent:\n    sentiment.append(item)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentiment[0:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet[0:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab = 40000\nmax_length = 500\nembedding_dim = 128\ntrunc_type = 'post'\npad_type = 'post'\noov_tok = \"<OOV>\"\ntraining_size = 40000","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_tweets = tweet[0:training_size]\ntraining_labels = sentiment[0:training_size]\ntest_sentence = tweet[training_size:]\ntest_label = sentiment[training_size:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words = vocab, oov_token = oov_tok)\ntokenizer.fit_on_texts(training_tweets)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_index = tokenizer.word_index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_seq = tokenizer.texts_to_sequences(training_tweets)\ntrain_pad = pad_sequences(train_seq, maxlen = max_length, padding = pad_type, truncating = trunc_type)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_seq = tokenizer.texts_to_sequences(test_sentence)\ntest_pad = pad_sequences(test_seq, maxlen = max_length, padding = pad_type, truncating = trunc_type)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = np.array(train_pad)\ntrain_label = np.array(training_labels)\ntest = np.array(test_pad)\ntest_label = np.array(test_label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Embedding\nfrom keras.layers.convolutional import Conv1D\nfrom keras.layers.convolutional import MaxPooling1D","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(vocab, embedding_dim, input_length=max_length))\nmodel.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss = 'binary_crossentropy',optimizer = 'Adam', metrics =['accuracy'] )\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epoch = 50\nmodel.fit(train, train_label, epochs=num_epoch, verbose = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}